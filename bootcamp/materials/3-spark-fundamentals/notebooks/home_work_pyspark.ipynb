{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36d15e26-1a09-4a81-825d-8157aa2efec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import broadcast, split, lit,col\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "317974d1-585d-4d06-a44f-84fd1a3265cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_medals = spark.read.option(\"header\", \"true\")\\\n",
    "                        .option(\"inferSchema\", \"true\")\\\n",
    "                        .csv(\"/home/iceberg/data/medals.csv\")\n",
    "\n",
    "df_medalsMatchesPlayers = spark.read.option(\"header\", \"true\")\\\n",
    "                        .option(\"inferSchema\", \"true\")\\\n",
    "                        .csv(\"/home/iceberg/data/medals_matches_players.csv\")\n",
    "\n",
    "df_explicitBroadcastMedalsMatchesPlayers = df_medalsMatchesPlayers.join(broadcast(df_medals), \"medal_id\",\"inner\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "88d1fc53-b313-4f67-8791-5776ad9b17be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_maps = spark.read.option(\"header\", \"true\")\\\n",
    "                       .option(\"inferSchema\", \"true\")\\\n",
    "                        .csv(\"/home/iceberg/data/maps.csv\")\n",
    "\n",
    "df_matches = spark.read.option(\"header\", \"true\")\\\n",
    "                        .option(\"inferSchema\", \"true\")\\\n",
    "                        .csv(\"/home/iceberg/data/matches.csv\")\n",
    "\n",
    "df_explicitBroadcastMatchesMaps = df_matches.join(broadcast(df_maps), \"mapid\", \"inner\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed5dda3-9143-4c3f-a86d-52997eadda2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 14:>                                                         (0 + 1) / 1]\r"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.matches_bucketed\"\"\")\n",
    "matches_bucketed_DDL = \"\"\"\n",
    " CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     player_total_kills INTEGER,\n",
    "     player_total_deaths INTEGER\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (bucket(16, match_id));\n",
    " \"\"\"\n",
    "spark.sql(matches_bucketed_DDL)\n",
    "\n",
    "df_matches.select(\n",
    "     col(\"match_id\"), col(\"mapid\"), col(\"is_team_game\"), col(\"playlist_id\"), col(\"completion_date\"))\\\n",
    "     .write.mode(\"overwrite\")\\\n",
    "    .partitionBy(\"completion_date\")\\\n",
    "     .bucketBy(16, \"match_id\")\\\n",
    "    .saveAsTable(\"bootcamp.match_details_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e829b6d8-92f2-4a72-a61d-7f0b6ac71ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_matchDetails =  spark.read.option(\"header\", \"true\")\\\n",
    "                        .option(\"inferSchema\", \"true\")\\\n",
    "                        .csv(\"/home/iceberg/data/match_details.csv\")\n",
    "\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.match_details_bucketed\"\"\")\n",
    "matchDetailBucketedDDL = \"\"\"\n",
    " CREATE TABLE IF NOT EXISTS bootcamp.match_details_bucketed (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     player_total_kills INTEGER,\n",
    "     player_total_deaths INTEGER\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (bucket(16, match_id));\n",
    " \"\"\"\n",
    "spark.sql(matchDetailBucketedDDL)\n",
    "\n",
    "df_matchDetails.select(\n",
    "     col(\"match_id\"), col(\"player_gamertag\"), col(\"player_total_kills\"),col(\"player_total_deaths\"))\\\n",
    "     .write.mode(\"overwrite\")\\\n",
    "   .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.match_details_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b309d93-e00a-41f7-9aa8-aace01b0c8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# medals Matches Players\n",
    "\n",
    "spark.sql(\"\"\"DROP TABLE IF EXISTS bootcamp.medals_match_players_bucketed\"\"\")\n",
    "medalsMatchesPlayers = \"\"\"\n",
    " CREATE TABLE IF NOT EXISTS bootcamp.medals_match_players_bucketed (\n",
    "     match_id STRING,\n",
    "     player_gamertag STRING,\n",
    "     medal_id STRING,\n",
    "     count INTEGER\n",
    " )\n",
    " USING iceberg\n",
    " PARTITIONED BY (bucket(16, match_id));\n",
    " \"\"\"\n",
    "spark.sql(medalsMatchesPlayers)\n",
    "\n",
    "df_medalsMatchesPlayers.select(\n",
    "     col(\"match_id\"), col(\"player_gamertag\"), col(\"medal_id\"), col(\"count\"))\\\n",
    "     .write.mode(\"overwrite\")\\\n",
    "   .bucketBy(16, \"match_id\").saveAsTable(\"bootcamp.medals_match_players_bucketed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
